{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.execute_input":"2024-10-02T08:15:10.497576Z","iopub.status.busy":"2024-10-02T08:15:10.497136Z","iopub.status.idle":"2024-10-02T08:15:11.859223Z","shell.execute_reply":"2024-10-02T08:15:11.858237Z","shell.execute_reply.started":"2024-10-02T08:15:10.497531Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = torch.tensor([1.00, 2.5])\n","X"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Y = torch.tensor([[1.7, 2.3, 3.1], [4.8, 5.3, 6.5]])\n","Y"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Z = torch.tensor([[[1.7, 2.3, 3.1], [4.8, 5.3, 6.5]],[[8.6, 2.0, 9.2], [1.4, 7.2, 3.5]]])\n","Z"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Y[0,2]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Y**2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X@Y"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Y*Y"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.inverse(Y.t() @ Y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Y.to('cpu')"]},{"cell_type":"markdown","metadata":{},"source":["Gradient calculation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = torch.randint(10, (1,2), dtype=torch.float)\n","display(X)\n","print(\"X.requires_grad :\", X.requires_grad)"]},{"cell_type":"markdown","metadata":{},"source":["Lets define a function $f(x,y) = $ sin $(x.y)$"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = torch.Tensor([1, 2, 3]).requires_grad_(True)\n","Y = torch.Tensor([5, 6, 7]).requires_grad_(True)\n","\n","f = torch.sin(torch.dot(X,Y))\n","print(\"f =\", f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"X.grad :\", X.grad)\n","print(\"Y.grad :\", Y.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f.backward()\n","print(\"X.grad :\", X.grad)\n","print(\"Y.grad :\", Y.grad)"]},{"cell_type":"markdown","metadata":{},"source":["We can also do the calculation manually"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfdx = torch.cos(torch.dot(X,Y)) * Y\n","dfdx"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfdy = torch.cos(torch.dot(X,Y)) * X\n","dfdy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["A = torch.Tensor([[1, 2], [3, 4]])\n","A.requires_grad_()\n","\n","B = 5 * (A + A)\n","C = B.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(A.grad_fn)\n","print(B.grad_fn)\n","print(C.grad_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["C.grad_fn.next_functions"]},{"cell_type":"markdown","metadata":{},"source":["Using optimisers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def square_function(x):\n","    return x ** 2 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x0 = 8\n","lr = 0.5\n","\n","x = torch.Tensor([x0]).requires_grad_()\n","optimizer = torch.optim.SGD([x], lr=lr)\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.8)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(4):\n","    optimizer.zero_grad()\n","    y = square_function(x)\n","    y.backward()\n","    optimizer.step()\n","    scheduler.step()\n","    print(y.data, \" | lr : \", optimizer.param_groups[0]['lr'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def more_difficult_function(x):\n","    return x ** 2 / 20 + x.sin().tanh()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x0 = 8\n","lr = 0.5\n","\n","x = torch.Tensor([x0]).requires_grad_()\n","optimizer = torch.optim.SGD([x], lr=lr)\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.8)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(15):\n","    optimizer.zero_grad()\n","    y = more_difficult_function(x)\n","    y.backward()\n","    optimizer.step()\n","    scheduler.step()\n","    print(y.data, \" | lr : \", optimizer.param_groups[0]['lr'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = None\n","ax = None\n","\n","def init_2dplot(x_range, func):\n","    global fig, ax\n","    fig = plt.figure(figsize=(8, 6), dpi=120)\n","    ax = fig.gca()\n","    fig.canvas.draw()\n","    \n","    y = func(x_range)\n","    ax.plot(x_range.numpy(), y.numpy(), 'b', alpha=0.2)\n","    \n","def add_point_2d(x, y, i, colour):\n","    ax.scatter(x.data.numpy(), y.data.numpy(), c=colour, edgecolors='k', linewidth=.5, alpha=0.4)\n","    ax.text(x.data.numpy()[0] + 0.1, y.data.numpy()[0] + 0.1, str(i))\n","    fig.canvas.draw()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x0 = 8\n","lr = 1\n","iterations = 20\n","\n","x_range = torch.arange(-10, 10, 0.1)\n","init_2dplot(x_range, more_difficult_function)\n","\n","x = torch.Tensor([x0]).requires_grad_()\n","optimizer = torch.optim.Adam([x], lr=lr)\n","# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 1)\n","\n","for i in range(iterations):\n","    optimizer.zero_grad()\n","    f = more_difficult_function(x)\n","    f.backward()\n","    add_point_2d(x, f, i, 'r')\n","    optimizer.step()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MyFirstNN(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(MyFirstNN, self).__init__()  \n","        self.linear = nn.Linear(input_size, num_classes) \n","    \n","    def forward(self, x):\n","        out = self.linear(x)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = MyFirstNN(input_size=20, num_classes=5)\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.rand(10000, 20)\n","out = model(x)\n","out[:3,:]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for name, p in model.named_parameters():\n","    print(name, \":\\n\", p)  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_model(iter, model, x, y, lr):\n","    criterion = torch.nn.MSELoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n","    loss_vector = []\n","\n","    for epoch in range(iter):\n","        y1 = model(x)\n","        loss = criterion(y1, y)\n","        loss_vector.append(loss.item())\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    return loss_vector"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = torch.rand(10000, 5)\n","y[:,0] = np.round(x[:,3] + x[:,5] + x[:,7])\n","y[:,1] = np.round(x[:,13] + x[:,15] + x[:,17] + x[:,19])\n","y[:,2] = np.round(x[:,2] + x[:,4])\n","y[:,3] = np.round(x[:,0] + x[:,1] - x[:,6])\n","y[:,4] = np.round(x[:,8] + x[:,9] + x[:,10] + x[:,11] - x[:,12] - x[:,14])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["losses = train_model(200, model, x, y, 0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["out = model(x)\n","display(y[:3,:])\n","display(out[:3,:])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MyMultilayerPerceptron(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(MyMultilayerPerceptron, self).__init__()\n","        \n","        self.input_size = input_size\n","        self.num_classes = num_classes\n","        \n","        self.linear_1 = nn.Linear(input_size, 75)\n","        self.linear_2 = nn.Linear(75, 50)\n","        self.linear_3 = nn.Linear(50, num_classes)\n","    \n","    def forward(self, x):\n","        x = torch.nn.functional.relu(self.linear_1(x))\n","        x = torch.nn.functional.relu(self.linear_2(x))\n","        x = self.linear_3(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_2 = MyMultilayerPerceptron(20, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["losses = train_model(2000, model_2, x, y, 0.3)\n","plt.plot(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["out_2 = model_2(x)\n","display(y[:3,:])\n","display(out[:3,:])\n","display(out_2[:3,:])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(np.mean(np.abs(y.numpy()-out.detach().numpy().tolist()), axis=0))\n","print(np.mean(np.abs(y.numpy()-out_2.detach().numpy().tolist()), axis=0))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class NewNN(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(NewNN, self).__init__()\n","        \n","        self.input_size = input_size\n","        self.num_classes = num_classes\n","        \n","        self.linear_1 = nn.Linear(input_size, 10)\n","        self.linear_2 = nn.Linear(5, 5)\n","        self.linear_3 = nn.Linear(5, 5)\n","        self.linear_4 = nn.Linear(10, num_classes)\n","    \n","    def forward(self, x):\n","        x0 = torch.nn.functional.relu(self.linear_1(x))\n","        x1 = torch.nn.functional.relu(self.linear_2(x0[:,5:]))\n","        x2 = self.linear_3(x0[:,:5])\n","        x3 = self.linear_4(torch.cat((x2, x1), dim=1))\n","        return x3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_3 = NewNN(20, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["losses = train_model(200, model_3, x, y, 0.2)\n","plt.plot(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["out_3 = model_3(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(np.mean(np.abs(y.numpy()-out.detach().numpy().tolist()), axis=0))\n","print(np.mean(np.abs(y.numpy()-out_2.detach().numpy().tolist()), axis=0))\n","print(np.mean(np.abs(y.numpy()-out_3.detach().numpy().tolist()), axis=0))"]},{"cell_type":"markdown","metadata":{},"source":["Other layers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Strength: Reduces overfitting by randomly setting a fraction of input units to zero during training.\n","class DropoutExample(nn.Module):\n","    def __init__(self):\n","        super(DropoutExample, self).__init__()\n","        self.fc = nn.Linear(10, 5)\n","        self.dropout = nn.Dropout(p=0.5)\n","\n","    def forward(self, x):\n","        x = self.fc(x)\n","        return self.dropout(x)\n","\n","model = DropoutExample()\n","input_data = torch.randn(1, 10)\n","output = model(input_data)\n","print(output)  # Output with dropout applied"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Strength: Normalizes the output of a previous activation layer, improving convergence and stability.\n","class BatchNormExample(nn.Module):\n","    def __init__(self):\n","        super(BatchNormExample, self).__init__()\n","        self.fc = nn.Linear(10, 5)\n","        self.batch_norm = nn.BatchNorm1d(5)\n","        self.fc2 = nn.Linear(5, 1)\n","\n","    def forward(self, x):\n","        x = self.fc(x)\n","        x = self.batch_norm(x)\n","        x = torch.nn.functional.relu(x)\n","        return self.fc2(x)\n","\n","model = BatchNormExample()\n","input_data = torch.randn(2, 10)\n","output = model(input_data)\n","print(output)  # Output after batch normalization"]},{"cell_type":"markdown","metadata":{},"source":["Time series"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Strength: Good for processing sequential data, such as time series\n","class Conv1DExample(nn.Module):\n","    def __init__(self):\n","        super(Conv1DExample, self).__init__()\n","        self.conv1d = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3)\n","\n","    def forward(self, x):\n","        return self.conv1d(x)\n","\n","model = Conv1DExample()\n","input_data = torch.randn(1, 1, 10)  # Batch size of 1, 1 channel, sequence length of 10\n","output = model(input_data)\n","print(output.shape)  # Output shape: (1, 16, 8) (due to kernel size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Strength: Effective for sequence data, capturing long-term dependencies.\n","class LSTMExample(nn.Module):\n","    def __init__(self):\n","        super(LSTMExample, self).__init__()\n","        self.lstm = nn.LSTM(input_size=10, hidden_size=5)\n","\n","    def forward(self, x):\n","        x, _ = self.lstm(x)  # x shape: (sequence_length, batch_size, input_size)\n","        return x\n","\n","model = LSTMExample()\n","input_data = torch.randn(5, 1, 10)  # Sequence length of 5, batch size of 1, input size of 10\n","output = model(input_data)\n","print(output.shape)  # Output shape: (5, 1, 5)"]},{"cell_type":"markdown","metadata":{},"source":["Image/video data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Strength: Reduces dimensionality, helps with translational invariance.\n","class PoolingExample(nn.Module):\n","    def __init__(self):\n","        super(PoolingExample, self).__init__()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","    def forward(self, x):\n","        return self.pool(x)\n","\n","model = PoolingExample()\n","input_data = torch.randn(1, 16, 28, 28)  # 16 channels, 28x28 feature map\n","output = model(input_data)\n","print(output.shape)  # Output shape: (1, 16, 14, 14)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Strength: Effective for image data, capturing spatial hierarchies.\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # 1 input channel, 16 output channels\n","\n","    def forward(self, x):\n","        return self.conv1(x)\n","\n","model = SimpleCNN()\n","input_data = torch.randn(1, 1, 28, 28)  # Batch of 1, 1 channel, 28x28 image\n","output = model(input_data)\n","print(output.shape)  # Output shape: (1, 16, 28, 28)"]},{"cell_type":"markdown","metadata":{},"source":["Text data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Strength: Captures relationships between all elements in a sequence, enhancing performance in tasks like translation.\n","class AttentionExample(nn.Module):\n","    def __init__(self):\n","        super(AttentionExample, self).__init__()\n","        self.attention = nn.MultiheadAttention(embed_dim=10, num_heads=2)\n","\n","    def forward(self, x):\n","        x, _ = self.attention(x, x, x)  # x shape: (sequence_length, batch_size, embed_dim)\n","        return x\n","\n","model = AttentionExample()\n","input_data = torch.randn(5, 1, 10)  # Sequence length of 5, batch size of 1, embedding size of 10\n","output = model(input_data)\n","print(output.shape)  # Output shape: (5, 1, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Strength: Efficiently converts categorical variables into dense vectors, especially useful in NLP tasks.\n","class EmbeddingExample(nn.Module):\n","    def __init__(self):\n","        super(EmbeddingExample, self).__init__()\n","        self.embedding = nn.Embedding(num_embeddings=10, embedding_dim=3)  # 10 categories, 3-dimensional vectors\n","\n","    def forward(self, x):\n","        return self.embedding(x)\n","\n","model = EmbeddingExample()\n","input_data = torch.tensor([1, 2, 3])  # Indices of categories\n","output = model(input_data)\n","print(output)  # Output: Dense vector representation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3326190,"sourceId":5791434,"sourceType":"datasetVersion"}],"dockerImageVersionId":30497,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
