{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.execute_input":"2024-10-02T08:15:10.497576Z","iopub.status.busy":"2024-10-02T08:15:10.497136Z","iopub.status.idle":"2024-10-02T08:15:11.859223Z","shell.execute_reply":"2024-10-02T08:15:11.858237Z","shell.execute_reply.started":"2024-10-02T08:15:10.497531Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import random\n","from zipfile import ZipFile\n","from sklearn.model_selection import train_test_split\n","import datetime\n","from torch.utils.tensorboard.writer import SummaryWriter"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with ZipFile('pc6.zip') as zip_file:\n","    names = zip_file.namelist()\n","    with zip_file.open(names[0]) as data_file:\n","        df = pd.read_csv(data_file, index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-10-01T10:34:53.392751Z","iopub.status.busy":"2023-10-01T10:34:53.391854Z","iopub.status.idle":"2023-10-01T10:34:53.749436Z","shell.execute_reply":"2023-10-01T10:34:53.7482Z","shell.execute_reply.started":"2023-10-01T10:34:53.392706Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(df.describe(include='all').transpose())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-01T10:34:58.922113Z","iopub.status.busy":"2023-10-01T10:34:58.921508Z","iopub.status.idle":"2023-10-01T10:35:01.201472Z","shell.execute_reply":"2023-10-01T10:35:01.199925Z","shell.execute_reply.started":"2023-10-01T10:34:58.92207Z"},"trusted":true},"outputs":[],"source":["variables = df.columns.drop('PC6')\n","data = df[variables]\n","correlation_matrix = data.corr()\n","mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n","\n","plt.figure(figsize=(12, 10))\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, mask=mask)\n","plt.title('Correlation Matrix')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['P_VROUW'] = df['VROUW']/df['INWONER']\n","df = df.drop(columns=['MAN', 'VROUW'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = df['WOZWONING'] > df['WOZWONING'].mean()\n","X = df.drop(columns=['WOZWONING','PC6']).fillna(-1)"]},{"cell_type":"markdown","metadata":{},"source":["Setting the random seeds for reproducibility"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.initial_seed()\n","np.random.seed(0)\n","random.seed(0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(torch.tensor(X.values, dtype=torch.float32), \n","                                                    torch.tensor(y.values, dtype=torch.float32).reshape(-1, 1), \n","                                                    train_size=0.7, \n","                                                    shuffle=True,\n","                                                    random_state=0)\n","train_loader = torch.utils.data.DataLoader(list(zip(X_train, y_train)),\n","                                           batch_size=10,\n","                                           num_workers=1)\n","test_loader = torch.utils.data.DataLoader(list(zip(X_test, y_test)),\n","                                          batch_size=10,\n","                                          num_workers=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MyModel(nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","\n","        self.d1 = nn.Linear(18,4)\n","        self.d2 = nn.Linear(4, 1)\n","\n","    def forward(self, x):\n","        x = self.d1(x)\n","        x = nn.functional.relu(x)\n","        logits = self.d2(x)\n","        out = nn.functional.softmax(logits, dim=1)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = MyModel()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","loss_function = torch.nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_one_epoch(epoch_index, tb_writer):\n","    running_loss = 0.\n","    last_loss = 0.\n","\n","    for i, data in enumerate(train_loader):\n","        inputs, labels = data\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = loss_function(outputs, labels)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        if i % 1000 == 999:\n","            last_loss = running_loss / 1000 # loss per batch\n","            print('  batch {} loss: {}'.format(i + 1, last_loss))\n","            tb_x = epoch_index * len(train_loader) + i + 1\n","            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n","            running_loss = 0.\n","\n","    return last_loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epoch_number = 0\n","EPOCHS = 5\n","best_vloss = 1_000_000.\n","\n","timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n","writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n","\n","for epoch in range(EPOCHS):\n","    print('EPOCH {}:'.format(epoch_number + 1))\n","\n","    # Make sure gradient tracking is on, and do a pass over the data\n","    model.train(True)\n","    avg_loss = train_one_epoch(epoch_number, writer)\n","\n","\n","    running_vloss = 0.0\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for i, vdata in enumerate(test_loader):\n","            vinputs, vlabels = vdata\n","            voutputs = model(vinputs)\n","            vloss = loss_function(voutputs, vlabels)\n","            running_vloss += vloss\n","\n","    avg_vloss = running_vloss / (i + 1)\n","    print(f'LOSS train {avg_loss} valid {avg_vloss}')\n","\n","    epoch_number += 1"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3326190,"sourceId":5791434,"sourceType":"datasetVersion"}],"dockerImageVersionId":30497,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
